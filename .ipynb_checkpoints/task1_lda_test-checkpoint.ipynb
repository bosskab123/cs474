{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d660d0b3",
   "metadata": {},
   "source": [
    "### Libs & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c941fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kwsst\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kwsst\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import string\n",
    "import random\n",
    "import unicodedata\n",
    "from string import punctuation\n",
    "from string import digits\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import joblib\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# from sklearn.metrics import silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "# from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deed989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015 = pd.read_csv(\"data/df2015.csv\")\n",
    "df2016 = pd.read_csv(\"data/df2016.csv\")\n",
    "df2017 = pd.read_csv(\"data/df2017.csv\")\n",
    "df2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d2676f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2015</th>\n",
       "      <th>label2015</th>\n",
       "      <th>freq2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>label2016</th>\n",
       "      <th>freq2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>label2017</th>\n",
       "      <th>freq2017</th>\n",
       "      <th>sents2015</th>\n",
       "      <th>sents2016</th>\n",
       "      <th>sents2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South Korea reported no additional cases of Mi...</td>\n",
       "      <td>2957</td>\n",
       "      <td>6</td>\n",
       "      <td>Radio Pyongyang, the North's state-run radio s...</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>Temperatures across the country plummeted abou...</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>South Korea reported no additional cases of Mi...</td>\n",
       "      <td>Radio Pyongyang, the North's state-run radio s...</td>\n",
       "      <td>Temperatures across the country plummeted abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In October, some 36,900 babies were born, up 1...</td>\n",
       "      <td>132</td>\n",
       "      <td>5</td>\n",
       "      <td>Some 200 chickens were found dead on Monday mo...</td>\n",
       "      <td>518</td>\n",
       "      <td>4</td>\n",
       "      <td>A South Korean research team says it has uncov...</td>\n",
       "      <td>617</td>\n",
       "      <td>7</td>\n",
       "      <td>In October, some 36,900 babies were born, up 1...</td>\n",
       "      <td>Some 200 chickens were found dead on Monday mo...</td>\n",
       "      <td>A South Korean research team says it has uncov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cho Hyun-ah, former vice president of Korean A...</td>\n",
       "      <td>6018</td>\n",
       "      <td>4</td>\n",
       "      <td>Voter turnout in South Korea’s parliamentary e...</td>\n",
       "      <td>5095</td>\n",
       "      <td>4</td>\n",
       "      <td>South Korean scientists have developed an adhe...</td>\n",
       "      <td>4735</td>\n",
       "      <td>5</td>\n",
       "      <td>Cho Hyun-ah, former vice president of Korean A...</td>\n",
       "      <td>Just less than 60 percent of South Korean vote...</td>\n",
       "      <td>A group of South Korean scientists have develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seoul-Tokyo ties have plunged to lowest levels...</td>\n",
       "      <td>5457</td>\n",
       "      <td>4</td>\n",
       "      <td>Walkway along Deoksu Palace in downtown Seoul ...</td>\n",
       "      <td>705</td>\n",
       "      <td>3</td>\n",
       "      <td>About 30,300 babies were born in May, down 11....</td>\n",
       "      <td>3708</td>\n",
       "      <td>5</td>\n",
       "      <td>South Korea and Japan held talks on Tokyo's se...</td>\n",
       "      <td>Some 100 meters of walkway by the famous stone...</td>\n",
       "      <td>About 30,300 babies were born in May, down 11....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Korea's top financial regulator said Fri...</td>\n",
       "      <td>5039</td>\n",
       "      <td>4</td>\n",
       "      <td>Pigs at two swine farms in Nonsan in the centr...</td>\n",
       "      <td>5782</td>\n",
       "      <td>3</td>\n",
       "      <td>The search for the missing South Korean ship, ...</td>\n",
       "      <td>6654</td>\n",
       "      <td>4</td>\n",
       "      <td>South Korea's top financial regulator said Fri...</td>\n",
       "      <td>Pigs at two swine farms in Nonsan in the centr...</td>\n",
       "      <td>Brazilian Air Force has mobilized an aircraft ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                2015  label2015  freq2015  \\\n",
       "0  South Korea reported no additional cases of Mi...       2957         6   \n",
       "1  In October, some 36,900 babies were born, up 1...        132         5   \n",
       "2  Cho Hyun-ah, former vice president of Korean A...       6018         4   \n",
       "3  Seoul-Tokyo ties have plunged to lowest levels...       5457         4   \n",
       "4  South Korea's top financial regulator said Fri...       5039         4   \n",
       "\n",
       "                                                2016  label2016  freq2016  \\\n",
       "0  Radio Pyongyang, the North's state-run radio s...         16         5   \n",
       "1  Some 200 chickens were found dead on Monday mo...        518         4   \n",
       "2  Voter turnout in South Korea’s parliamentary e...       5095         4   \n",
       "3  Walkway along Deoksu Palace in downtown Seoul ...        705         3   \n",
       "4  Pigs at two swine farms in Nonsan in the centr...       5782         3   \n",
       "\n",
       "                                                2017  label2017  freq2017  \\\n",
       "0  Temperatures across the country plummeted abou...         67        11   \n",
       "1  A South Korean research team says it has uncov...        617         7   \n",
       "2  South Korean scientists have developed an adhe...       4735         5   \n",
       "3  About 30,300 babies were born in May, down 11....       3708         5   \n",
       "4  The search for the missing South Korean ship, ...       6654         4   \n",
       "\n",
       "                                           sents2015  \\\n",
       "0  South Korea reported no additional cases of Mi...   \n",
       "1  In October, some 36,900 babies were born, up 1...   \n",
       "2  Cho Hyun-ah, former vice president of Korean A...   \n",
       "3  South Korea and Japan held talks on Tokyo's se...   \n",
       "4  South Korea's top financial regulator said Fri...   \n",
       "\n",
       "                                           sents2016  \\\n",
       "0  Radio Pyongyang, the North's state-run radio s...   \n",
       "1  Some 200 chickens were found dead on Monday mo...   \n",
       "2  Just less than 60 percent of South Korean vote...   \n",
       "3  Some 100 meters of walkway by the famous stone...   \n",
       "4  Pigs at two swine farms in Nonsan in the centr...   \n",
       "\n",
       "                                           sents2017  \n",
       "0  Temperatures across the country plummeted abou...  \n",
       "1  A South Korean research team says it has uncov...  \n",
       "2  A group of South Korean scientists have develo...  \n",
       "3  About 30,300 babies were born in May, down 11....  \n",
       "4  Brazilian Air Force has mobilized an aircraft ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/top20sum_sents.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fefa73f",
   "metadata": {},
   "source": [
    "### LDA on summarized body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a873ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(s: str):\n",
    "    # Change similar terms to the same term\n",
    "    new_str = text_cleaning(s)\n",
    "    doc = nlp(s)\n",
    "    # Group tokens\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    token_groupup_pattern = [\n",
    "        [{\"LOWER\": \"the\"}, {\"LOWER\": \"united\"}, {\"LOWER\": \"nations\"}],\n",
    "        [{\"LOWER\": \"the\"}, {\"LOWER\": \"united\"}, {\"LOWER\": \"states\"}],\n",
    "        [{\"LOWER\": \"north\"}, {\"LOWER\": \"korea\"}],\n",
    "        [{\"LOWER\": \"south\"}, {\"LOWER\": \"korea\"}],\n",
    "    ]\n",
    "    matcher.add(\"TermGroup\",token_groupup_pattern)\n",
    "    matches = matcher(doc)\n",
    "    merge_doc = []\n",
    "    for nid, start, end in matches:\n",
    "        merge_doc.append((start,end))\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for i in range(len(merge_doc)-1,-1,-1):\n",
    "            retokenizer.merge(doc[merge_doc[i][0]:merge_doc[i][1]])\n",
    "        \n",
    "    # Remove all stopword, punctuation, number\n",
    "    tokens = [ token.lemma_.lower() for token in doc \\\n",
    "              if not token.is_stop and not token.is_punct and not token.like_num and token.lemma_.strip()!= '']\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, min_df=2)\n",
    "all_texts = df['sents2015']\n",
    "data_vectorized = vectorizer.fit_transform(tqdm(all_texts))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76905c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, vectorizer, n_top_words):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"\\nTopic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model LDA\n",
    "lda2015 = joblib.load('data/lda_title_2015.csv')\n",
    "lda2016 = joblib.load('data/lda_title_2016.csv')\n",
    "lda2017 = joblib.load('data/lda_title_2017.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_words(lda2015, vectorizer, n_top_words=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c95d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_words(lda2016, vectorizer, n_top_words=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8860f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_words(lda2017, vectorizer, n_top_words=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmining",
   "language": "python",
   "name": "tmining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
